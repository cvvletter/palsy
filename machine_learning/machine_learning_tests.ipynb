{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine learning tests are run here\n",
    "Some code blocks always have to be run, some can be skipped if only certain tests are of interest."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports (mandatory)\n",
    "We start with importing some necessary packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# import matplotlib as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make the dataset (mandatory)\n",
    "Here, we make the dataset that we will use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the features\n",
    "dftrain = np.load('features.npy')\n",
    "# dftrain = dftrain[:,17:135] # discard some peripheral patients and the chin landmarks\n",
    "# load the corresponding labels\n",
    "y_train = np.load('labels.npy')\n",
    "# y_train = y_train[50:202] # discard the same peripheral patients\n",
    "\n",
    "dftrain = dftrain / 900.0\n",
    "\n",
    "classes = ['peripheral palsy', 'central palsy', 'healthy']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Print the dataset (optional)\n",
    "See the dataset that we're working with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features shape: (203, 136)\n",
      "Labels shape: (203,)\n"
     ]
    }
   ],
   "source": [
    "# print(\"Features:\", dftrain[0])\n",
    "# print(\"Labels:\", classes[y_train[0]])\n",
    "print(\"Features shape:\",dftrain.shape)\n",
    "print(\"Labels shape:\",y_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 1 (optional)\n",
    "This is the first experiment. A DNN is made with many different amounts of hidden layers and nodes. The final accuracy is printed using LOOCV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final accuracy = 0.5073891625615764\n"
     ]
    }
   ],
   "source": [
    "# imports:\n",
    "import tensorflow as tf\n",
    "\n",
    "# use leave-one-out cross-validation to test the accuracy of the model\n",
    "correct = 0\n",
    "n = len(y_train)\n",
    "for i in range(len(y_train)):\n",
    "    # print(\"Run\", i+1, \"of\", len(dftrain))\n",
    "    x_test = dftrain[i]\n",
    "    x_test = np.reshape(x_test, (1,-1))\n",
    "    y_test = y_train[i]\n",
    "    x_train_loocv = np.delete(dftrain, i, 0)\n",
    "    y_train_loocv = np.delete(y_train, i, 0)\n",
    "    model1 = tf.keras.Sequential([\n",
    "        # tf.keras.layers.Dense(136, activation='relu'),\n",
    "        tf.keras.layers.Dense(108800, activation='relu'),\n",
    "        # tf.keras.layers.Dense(10880, activation='relu'),\n",
    "        tf.keras.layers.Dense(3, activation='sigmoid'),\n",
    "    ])\n",
    "\n",
    "    model1.compile(\n",
    "        optimizer = tf.keras.optimizers.Adam(),\n",
    "        loss = tf.keras.losses.SparseCategoricalCrossentropy(),\n",
    "        metrics = tf.keras.metrics.CategoricalAccuracy(),\n",
    "    )\n",
    "    model1.fit(x_train_loocv, y_train_loocv, epochs=1, verbose=0, batch_size=len(x_train_loocv), shuffle=True)\n",
    "    prediction = np.argmax(model1.predict(x_test))\n",
    "    # print(\"Prediction:\", classes[prediction.astype(int)])\n",
    "    # print(\"Actual:    \", classes[y_test.astype(int)])\n",
    "    if (prediction == y_test):\n",
    "        correct += 1\n",
    "print(\"Final accuracy =\", correct/n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 2 (optional)\n",
    "This is the second experiment. A support vector machine (SVM) will be built."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final accuracy = 0.8078817733990148\n"
     ]
    }
   ],
   "source": [
    "# todo: higher weight for central palsy (most severe condition)\n",
    "\n",
    "# imports:\n",
    "from sklearn import svm\n",
    "\n",
    "# use leave-one-out cross-validation to test the accuracy of the model\n",
    "correct = 0\n",
    "n = len(y_train)\n",
    "for i in range(len(y_train)):\n",
    "    x_test = dftrain[i]\n",
    "    x_test = np.reshape(x_test, ([1,-1]))\n",
    "    y_test = y_train[i]\n",
    "    x_train_loocv = np.delete(dftrain, i, 0)\n",
    "    y_train_loocv = np.delete(y_train, i, 0)\n",
    "    model2 = svm.SVC(kernel='poly',degree=5)\n",
    "    model2.fit(x_train_loocv, y_train_loocv)\n",
    "    prediction = model2.predict(x_test)\n",
    "    if (prediction == y_test):\n",
    "        correct += 1\n",
    "print(\"Final accuracy =\", correct/n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 3 (optional)\n",
    "This is the third experiment. This model uses a K-nearest neighbors (KNN) algorithm to classify the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final accuracy = 0.7142857142857143\n"
     ]
    }
   ],
   "source": [
    "# imports:\n",
    "from sklearn import neighbors\n",
    "\n",
    "# model settings:\n",
    "n_neighbors = 5\n",
    "weight = 'distance'\n",
    "\n",
    "# use leave-one-out cross-validation to test the accuracy of the model\n",
    "correct = 0\n",
    "n = len(y_train)\n",
    "for i in range(len(y_train)):\n",
    "    x_test = dftrain[i]\n",
    "    x_test = np.reshape(x_test, ([1,-1]))\n",
    "    y_test = y_train[i]\n",
    "    x_train_loocv = np.delete(dftrain, i, 0)\n",
    "    y_train_loocv = np.delete(y_train, i, 0)\n",
    "    model3 = neighbors.KNeighborsClassifier(n_neighbors, weights=weight)\n",
    "    model3.fit(x_train_loocv, y_train_loocv)\n",
    "    prediction = model3.predict(x_test)\n",
    "    if (prediction == y_test):\n",
    "        correct += 1\n",
    "print(\"Final accuracy =\", correct/n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 4 (optional)\n",
    "This is the fourth model. A Random Forest classification system is used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final accuracy = 0.7586206896551724\n"
     ]
    }
   ],
   "source": [
    "# imports:\n",
    "from sklearn import ensemble\n",
    "\n",
    "# model settings:\n",
    "n_estimators = 136\n",
    "\n",
    "# use leave-one-out cross-validation to test the accuracy of the model\n",
    "correct = 0\n",
    "n = len(y_train)\n",
    "for i in range(len(y_train)):\n",
    "    x_test = dftrain[i]\n",
    "    x_test = np.reshape(x_test, ([1,-1]))\n",
    "    y_test = y_train[i]\n",
    "    x_train_loocv = np.delete(dftrain, i, 0)\n",
    "    y_train_loocv = np.delete(y_train, i, 0)\n",
    "    model4 = ensemble.RandomForestClassifier(n_estimators)\n",
    "    model4.fit(x_train_loocv, y_train_loocv)\n",
    "    prediction = model4.predict(x_test)\n",
    "    if (prediction == y_test):\n",
    "        correct += 1\n",
    "print(\"Final accuracy =\", correct/n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 5 (optional)\n",
    "This is the fifth model. A Gaussian Naive Bayes model is built here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final accuracy = 0.6009852216748769\n"
     ]
    }
   ],
   "source": [
    "# imports:\n",
    "from sklearn import naive_bayes\n",
    "\n",
    "# model settings:\n",
    "\n",
    "# use leave-one-out cross-validation to test the accuracy of the model\n",
    "correct = 0\n",
    "n = len(y_train)\n",
    "for i in range(len(y_train)):\n",
    "    x_test = dftrain[i]\n",
    "    x_test = np.reshape(x_test, ([1,-1]))\n",
    "    y_test = y_train[i]\n",
    "    x_train_loocv = np.delete(dftrain, i, 0)\n",
    "    y_train_loocv = np.delete(y_train, i, 0)\n",
    "    model5 = naive_bayes.GaussianNB()\n",
    "    model5.fit(x_train_loocv, y_train_loocv)\n",
    "    prediction = model5.predict(x_test)\n",
    "    if (prediction == y_test):\n",
    "        correct += 1\n",
    "print(\"Final accuracy =\", correct/n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 6 (optional)\n",
    "This is the sixth model. A decision tree is used in the following code block."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports:\n",
    "from sklearn import tree\n",
    "\n",
    "# model settings:\n",
    "depth = 3\n",
    "\n",
    "# use leave-one-out cross-validation to test the accuracy of the model\n",
    "correct = 0\n",
    "n = len(y_train)\n",
    "for i in range(len(y_train)):\n",
    "    x_test = dftrain[i]\n",
    "    x_test = np.reshape(x_test, ([1,-1]))\n",
    "    y_test = y_train[i]\n",
    "    x_train_loocv = np.delete(dftrain, i, 0)\n",
    "    y_train_loocv = np.delete(y_train, i, 0)\n",
    "    model6 = tree.DecisionTreeClassifier(max_depth=depth)\n",
    "    model6.fit(x_train_loocv, y_train_loocv)\n",
    "    prediction = model6.predict(x_test)\n",
    "    if (prediction == y_test):\n",
    "        correct += 1\n",
    "print(\"Final accuracy =\", correct/n)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
