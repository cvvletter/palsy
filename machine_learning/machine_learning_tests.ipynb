{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine learning tests are run here\n",
    "This notebook shows several experiments on the (raw) palsy dataset, using different types of machine learning algorithms.\n",
    "\n",
    "The first code blocks always have to be run, the reset (all experiments) can be run individually when interested in a certain algorithm type."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports and definitions\n",
    "Mandatory section.\n",
    "\n",
    "We start with importing some necessary packages and defning the function(s) used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "def print_confusion_matrix(matrix):\n",
    "    print(\"    p  c  h\")\n",
    "    print('p',matrix[0])\n",
    "    print('c',matrix[1])\n",
    "    print('h',matrix[2])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make the dataset\n",
    "Mandatory section.\n",
    "\n",
    "Here, we make the dataset that we will use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**Dataset summary**\n",
      "(datapoints, features) = (202, 136)\n",
      "102 peripheral palsy\n",
      "40 central palsy\n",
      "60 healthy\n"
     ]
    }
   ],
   "source": [
    "# dataset settings:\n",
    "full_features = True\n",
    "\n",
    "# load the features\n",
    "x_train = np.load('features.npy')\n",
    "x_train = np.delete(x_train,102,0) # remove the one broken datapoint\n",
    "\n",
    "# load the corresponding labels\n",
    "y_train = np.load('labels.npy')\n",
    "y_train = np.delete(y_train,102,0) # remove the one broken datapoint\n",
    "\n",
    "# (potentially) discard some data\n",
    "if not full_features: \n",
    "    # leave out the chin landmarks for more significant data\n",
    "    x_train = x_train[:,34:]\n",
    "\n",
    "# scale the data so every 'coordinate' is between 0 and 1,\n",
    "# this works because the coordinates are on a 900x900 grid.\n",
    "x_train = x_train / 900.0\n",
    "\n",
    "# define class names for use in printing predictions\n",
    "classes = {0:'peripheral palsy', 1:'central palsy', 2:'healthy'}\n",
    "count_classes = np.bincount(y_train)\n",
    "\n",
    "# print the size of the dataset\n",
    "print(\"**Dataset summary**\")\n",
    "print(\"(datapoints, features) =\", x_train.shape)\n",
    "print(count_classes[0], classes[0])\n",
    "print(count_classes[1], classes[1])\n",
    "print(count_classes[2], classes[2])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 1\n",
    "Optional section.\n",
    "\n",
    "This is the first experiment. \n",
    "A DNN is made with many different amounts of hidden layers and nodes. \n",
    "The final accuracy is printed using LOOCV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# source: adapted from https://www.freecodecamp.org/learn/machine-learning-with-python/\n",
    "\n",
    "# results: not-much-better-than-guessing accuracy. probably not enough datapoints available.\n",
    "\n",
    "# imports:\n",
    "import tensorflow as tf\n",
    "\n",
    "# use leave-one-out cross-validation to test the accuracy of the model\n",
    "correct = 0\n",
    "confusion_matrix = [[0,0,0], [0,0,0], [0,0,0]]\n",
    "n = len(y_train)\n",
    "for i in range(len(y_train)):\n",
    "    # print(\"Run\", i+1, \"of\", len(dftrain))\n",
    "    x_test = x_train[i]\n",
    "    x_test = np.reshape(x_test, (1,-1))\n",
    "    y_test = y_train[i]\n",
    "    x_train_loocv = np.delete(x_train, i, 0)\n",
    "    y_train_loocv = np.delete(y_train, i, 0)\n",
    "    model1 = tf.keras.Sequential([\n",
    "        tf.keras.layers.Dense(100000, activation='relu'),\n",
    "        tf.keras.layers.Dense(3, activation='sigmoid'),\n",
    "    ])\n",
    "\n",
    "    model1.compile(\n",
    "        optimizer = tf.keras.optimizers.Adam(),\n",
    "        loss = tf.keras.losses.SparseCategoricalCrossentropy(),\n",
    "        metrics = tf.keras.metrics.CategoricalAccuracy(),\n",
    "    )\n",
    "    model1.fit(x_train_loocv, y_train_loocv, epochs=1, verbose=0, batch_size=len(x_train_loocv), shuffle=True)\n",
    "    prediction = np.argmax(model1.predict(x_test))\n",
    "    # print(\"Prediction:\", classes[prediction.astype(int)])\n",
    "    # print(\"Actual:    \", classes[y_test.astype(int)])\n",
    "    if (prediction == y_test):\n",
    "        correct += 1\n",
    "    confusion_matrix[prediction][y_test] += 1\n",
    "print(\"accuracy =\", correct/n)\n",
    "print_confusion_matrix(confusion_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 2\n",
    "Optional section.\n",
    "\n",
    "This is the second experiment. A support vector machine (SVM) will be built."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# source: adapted from https://scikit-learn.org/stable/modules/svm.html#svm-classification\n",
    "\n",
    "# imports:\n",
    "from sklearn import svm\n",
    "\n",
    "# model settings:\n",
    "kernel = 'poly'\n",
    "degree = 4\n",
    "# weights = {0:0.5, 1:10.0, 2:1.5}\n",
    "weights = 'balanced'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# single run\n",
    "\n",
    "# results: (using kernel='poly', degree=5, weights='balanced')\n",
    "    # full data, full features: .822\n",
    "    # full data, part features: .847\n",
    "\n",
    "# use leave-one-out cross-validation to test the accuracy of the model\n",
    "correct = 0\n",
    "confusion_matrix = [[0,0,0], [0,0,0], [0,0,0]]\n",
    "n = len(y_train)\n",
    "for i in range(len(y_train)):\n",
    "    x_test = x_train[i]\n",
    "    x_test = np.reshape(x_test, ([1,-1]))\n",
    "    y_test = y_train[i]\n",
    "    x_train_loocv = np.delete(x_train, i, 0)\n",
    "    y_train_loocv = np.delete(y_train, i, 0)\n",
    "    model2 = svm.SVC(kernel=kernel,degree=degree,class_weight=weights)\n",
    "    model2.fit(x_train_loocv, y_train_loocv)\n",
    "    prediction = model2.predict(x_test)\n",
    "    if (prediction == y_test):\n",
    "        correct += 1\n",
    "    confusion_matrix[prediction[0]][y_test] += 1\n",
    "print(\"accuracy =\", correct/n)\n",
    "print_confusion_matrix(confusion_matrix)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# multiple runs\n",
    "\n",
    "# results:\n",
    "    # full features: 0.836 with degree=8\n",
    "    # part features: 0.861 with degree=5\n",
    "\n",
    "# settings:\n",
    "runs = 40\n",
    "accuracy = []\n",
    "\n",
    "for degree in range(1,runs+1):\n",
    "    print(\"Run\",degree,\"of\",runs)\n",
    "    correct = 0\n",
    "    confusion_matrix = [[0,0,0], [0,0,0], [0,0,0]]\n",
    "    n = len(y_train)\n",
    "    for i in range(len(y_train)):\n",
    "        x_test = x_train[i]\n",
    "        x_test = np.reshape(x_test, ([1,-1]))\n",
    "        y_test = y_train[i]\n",
    "        x_train_loocv = np.delete(x_train, i, 0)\n",
    "        y_train_loocv = np.delete(y_train, i, 0)\n",
    "        model2 = svm.SVC(kernel=kernel,degree=degree,class_weight=weights)\n",
    "        model2.fit(x_train_loocv, y_train_loocv)\n",
    "        prediction = model2.predict(x_test)\n",
    "        if (prediction == y_test):\n",
    "            correct += 1\n",
    "        confusion_matrix[prediction[0]][y_test] += 1\n",
    "    print(\"accuracy =\", correct/n)\n",
    "    accuracy.append(correct/n)\n",
    "\n",
    "# plot a graph for the degree and accuracy\n",
    "plt.plot(range(1,len(accuracy)+1), accuracy)\n",
    "plt.xlabel('Degrees of polynomial kernel function')\n",
    "plt.ylabel('Testing Accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 3\n",
    "Optional section.\n",
    "\n",
    "This is the third experiment. \n",
    "This model uses a K-nearest neighbors (KNN) algorithm to classify the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# source: adated from https://scikit-learn.org/stable/auto_examples/neighbors/plot_classification.html#sphx-glr-auto-examples-neighbors-plot-classification-py\n",
    "\n",
    "# results: (using n_neighbors=5, weight='distance')\n",
    "    # full features: .698\n",
    "    # part features: .752\n",
    "\n",
    "# imports:\n",
    "from sklearn import neighbors\n",
    "\n",
    "# model settings:\n",
    "n_neighbors = 5\n",
    "weight = 'distance'\n",
    "\n",
    "# use leave-one-out cross-validation to test the accuracy of the model\n",
    "correct = 0\n",
    "confusion_matrix = [[0,0,0], [0,0,0], [0,0,0]]\n",
    "n = len(y_train)\n",
    "for i in range(len(y_train)):\n",
    "    x_test = x_train[i]\n",
    "    x_test = np.reshape(x_test, ([1,-1]))\n",
    "    y_test = y_train[i]\n",
    "    x_train_loocv = np.delete(x_train, i, 0)\n",
    "    y_train_loocv = np.delete(y_train, i, 0)\n",
    "    model3 = neighbors.KNeighborsClassifier(n_neighbors, weights=weight)\n",
    "    model3.fit(x_train_loocv, y_train_loocv)\n",
    "    prediction = model3.predict(x_test)\n",
    "    if (prediction == y_test):\n",
    "        correct += 1\n",
    "    confusion_matrix[prediction[0]][y_test] += 1\n",
    "print(\"accuracy =\", correct/n)\n",
    "print_confusion_matrix(confusion_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 4\n",
    "Optional section.\n",
    "\n",
    "This is the fourth experiment. \n",
    "A Random Forest classification system is used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# source: adapted from https://scikit-learn.org/stable/modules/ensemble.html#forest\n",
    "\n",
    "# imports:\n",
    "from sklearn import ensemble\n",
    "\n",
    "# model settings:\n",
    "n_estimators = 150\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# single run\n",
    "\n",
    "# results: (using n_estimators=136)\n",
    "    # full features: .767\n",
    "    # part features: .767\n",
    "\n",
    "# use leave-one-out cross-validation to test the accuracy of the model\n",
    "correct = 0\n",
    "confusion_matrix = [[0,0,0], [0,0,0], [0,0,0]]\n",
    "n = len(y_train)\n",
    "for i in range(len(y_train)):\n",
    "    x_test = x_train[i]\n",
    "    x_test = np.reshape(x_test, ([1,-1]))\n",
    "    y_test = y_train[i]\n",
    "    x_train_loocv = np.delete(x_train, i, 0)\n",
    "    y_train_loocv = np.delete(y_train, i, 0)\n",
    "    model4 = ensemble.RandomForestClassifier(n_estimators)\n",
    "    model4.fit(x_train_loocv, y_train_loocv,)\n",
    "    prediction = model4.predict(x_test)\n",
    "    if (prediction == y_test):\n",
    "        correct += 1\n",
    "    confusion_matrix[prediction[0]][y_test] += 1\n",
    "print(\"accuracy =\", correct/n)\n",
    "print_confusion_matrix(confusion_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# multiple runs\n",
    "\n",
    "# results: 0. (using  all features)\n",
    "\n",
    "# settings:\n",
    "runs = 500\n",
    "savestate_present = False\n",
    "\n",
    "# restore from savestate or make new array\n",
    "if (savestate_present):\n",
    "    accuracy = np.load('accuracy_randomforest.npy',)\n",
    "    accuracy = accuracy.tolist()\n",
    "else:\n",
    "    accuracy = []\n",
    "\n",
    "for n_estimators in range(len(accuracy)+1, runs):\n",
    "    # use leave-one-out cross-validation to test the accuracy of the model\n",
    "    print(\"Run\",n_estimators,\"of\",runs)\n",
    "    correct = 0\n",
    "    n = len(y_train)\n",
    "    for i in range(len(y_train)):\n",
    "        x_test = x_train[i]\n",
    "        x_test = np.reshape(x_test, ([1,-1]))\n",
    "        y_test = y_train[i]\n",
    "        x_train_loocv = np.delete(x_train, i, 0)\n",
    "        y_train_loocv = np.delete(y_train, i, 0)\n",
    "        model4 = ensemble.RandomForestClassifier(n_estimators, n_jobs=8)\n",
    "        model4.fit(x_train_loocv, y_train_loocv)\n",
    "        prediction = model4.predict(x_test)\n",
    "        if (prediction == y_test):\n",
    "            correct += 1\n",
    "    print(\"accuracy:\",correct/n)\n",
    "    accuracy.append(correct/n)\n",
    "\n",
    "    # save state for later continuance\n",
    "    np.save(\"accuracy_randomforest.npy\", accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = np.load(\"accuracy_randomforest.npy\")\n",
    "plt.plot(range(1,len(accuracy)+1), accuracy)\n",
    "plt.xlabel('Value of n_estimators for Random Forest Classifier')\n",
    "plt.ylabel('Testing Accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 5\n",
    "Optional section.\n",
    "\n",
    "This is the fifth experiment. \n",
    "A Gaussian Naive Bayes model is built here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# source: adapted from https://scikit-learn.org/stable/modules/naive_bayes.html\n",
    "\n",
    "# results: (no specific settings for this model)\n",
    "    # full features: .639\n",
    "    # part features: .644\n",
    "\n",
    "# imports:\n",
    "from sklearn import naive_bayes\n",
    "\n",
    "# model settings:\n",
    "\n",
    "# use leave-one-out cross-validation to test the accuracy of the model\n",
    "correct = 0\n",
    "confusion_matrix = [[0,0,0], [0,0,0], [0,0,0]]\n",
    "n = len(y_train)\n",
    "for i in range(len(y_train)):\n",
    "    x_test = x_train[i]\n",
    "    x_test = np.reshape(x_test, ([1,-1]))\n",
    "    y_test = y_train[i]\n",
    "    x_train_loocv = np.delete(x_train, i, 0)\n",
    "    y_train_loocv = np.delete(y_train, i, 0)\n",
    "    model5 = naive_bayes.GaussianNB()\n",
    "    model5.fit(x_train_loocv, y_train_loocv)\n",
    "    prediction = model5.predict(x_test)\n",
    "    if (prediction == y_test):\n",
    "        correct += 1\n",
    "    confusion_matrix[prediction[0]][y_test] += 1\n",
    "print(\"accuracy =\", correct/n)\n",
    "print_confusion_matrix(confusion_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 6\n",
    "Optional section.\n",
    "\n",
    "This is the sixth experiment. \n",
    "A decision tree is used in the following code block."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# source: adapted from https://scikit-learn.org/stable/modules/tree.html#classification\n",
    "\n",
    "# results: (using depth=10)\n",
    "    # full features: .678\n",
    "    # part features: .698\n",
    "\n",
    "# imports:\n",
    "from sklearn import tree\n",
    "\n",
    "# model settings:\n",
    "depth = 10\n",
    "\n",
    "# use leave-one-out cross-validation to test the accuracy of the model\n",
    "correct = 0\n",
    "confusion_matrix = [[0,0,0], [0,0,0], [0,0,0]]\n",
    "n = len(y_train)\n",
    "for i in range(len(y_train)):\n",
    "    x_test = x_train[i]\n",
    "    x_test = np.reshape(x_test, ([1,-1]))\n",
    "    y_test = y_train[i]\n",
    "    x_train_loocv = np.delete(x_train, i, 0)\n",
    "    y_train_loocv = np.delete(y_train, i, 0)\n",
    "    model6 = tree.DecisionTreeClassifier(max_depth=depth)\n",
    "    model6.fit(x_train_loocv, y_train_loocv)\n",
    "    prediction = model6.predict(x_test)\n",
    "    if (prediction == y_test):\n",
    "        correct += 1\n",
    "    confusion_matrix[prediction[0]][y_test] += 1\n",
    "print(\"Final accuracy =\", correct/n)\n",
    "print_confusion_matrix(confusion_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 7\n",
    "Optional section.\n",
    "\n",
    "This is the seventh experiment. \n",
    "A DNN is implemented here, this time using sklearn instead of tensorflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# source: adapted from https://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPClassifier.html#sklearn.neural_network.MLPClassifier\n",
    "\n",
    "# results: not working well, not much better than guessing.\n",
    "\n",
    "# imports:\n",
    "from sklearn import neural_network\n",
    "\n",
    "# model settings:\n",
    "solver = 'adam'\n",
    "alpha = 1e-5\n",
    "hidden_layers = (5)\n",
    "random = 1\n",
    "\n",
    "# use leave-one-out cross-validation to test the accuracy of the model\n",
    "correct = 0\n",
    "n = len(y_train)\n",
    "for i in range(len(y_train)):\n",
    "    x_test = x_train[i]\n",
    "    x_test = np.reshape(x_test, ([1,-1]))\n",
    "    y_test = y_train[i]\n",
    "    x_train_loocv = np.delete(x_train, i, 0)\n",
    "    y_train_loocv = np.delete(y_train, i, 0)\n",
    "    model7 = neural_network.MLPClassifier(solver=solver, alpha=alpha, hidden_layer_sizes=hidden_layers, random_state=random)\n",
    "    model7.fit(x_train_loocv, y_train_loocv)\n",
    "    prediction = model7.predict(x_test)\n",
    "    if (prediction == y_test):\n",
    "        correct += 1\n",
    "print(\"Final accuracy =\", correct/n)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
